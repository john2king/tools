1.basic definition

iteration： 数据进行一次前向-后向的训练
batchsize: 每次迭代训练图片的数量
epoch: 1个epoch就是将所有的训练图像全部通过网络训练一次

2.单独train多路conv然后在合并到一个fc没有意义，因为conv的结果本来就是局部特征，是并行计算而来的

3.形成从精确大网络到不那么精确的小网络的pipeline

4.随机梯度下降（SGD）是按batch来进行更新，通常来说下降速度比较快，但却容易造成另一个问题，就是更新过程不稳定，容易出现震荡。

引入momentum的idea是很直接的，就是在更新下降方向的时候不仅要考虑到当前的方向，也要考虑到上一次的更新方向，两者加权，某些情况下可以避免震荡。冲量，就是上一次更新方向所占的权值。

一个小的trick是，当刚开始训练的时候，把冲量设小，或者直接就置为0，然后慢慢增大冲量，有时候效果比较好。
